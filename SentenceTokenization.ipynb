{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitin649/Transformer-from-Scratch/blob/main/SentenceTokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXcI8iT9rjfM",
        "outputId": "4c06d35a-f0b7-46b3-ebfd-35aa62357679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/drive/MyDrive/Transformer_from_scratch/train.en.zip\n",
        "# !unzip /content/drive/MyDrive/Transformer_from_scratch/train.hi.zip\n"
      ],
      "metadata": {
        "id": "KA4X72aOtzKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import  numpy as np"
      ],
      "metadata": {
        "id": "JwcKR4YwrrMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = '/content/drive/MyDrive/Transformer_from_scratch/train.en'\n",
        "hindi_file = '/content/drive/MyDrive/Transformer_from_scratch/train.hi'"
      ],
      "metadata": {
        "id": "TAGqoXLFtqqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file) as file:\n",
        "    english_data = file.readlines()\n",
        "with open(hindi_file) as file:\n",
        "    hindi_data = file.readlines()"
      ],
      "metadata": {
        "id": "eQbAu99xuhWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(english_data[:2])\n",
        "print(hindi_data[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtOWbXapusGq",
        "outputId": "e89c91aa-18da-4bbd-a4a5-8c7a50bbc2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In reply, Pakistan got off to a solid start.\\n', 'The European Union has seven principal decision-making bodies, its institutions: the European Parliament, the European Council, the Council of the European Union, the European Commission, the Court of Justice of the European Union, the European Central Bank and the European Court of Auditors.\\n']\n",
            "['जिसके जवाब में पाक ने अच्छी शुरुआत की थी.\\n', 'यूरोपीय संघ के महत्वपूर्ण संस्थानों में यूरोपियन कमीशन, यूरोपीय संसद, यूरोपीय संघ परिषद, यूरोपीय न्यायलय एवं यूरोपियन सेंट्रल बैंक इत्यादि शामिल हैं।\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_data = english_data[:100000]\n",
        "hindi_data = hindi_data[:100000]\n",
        "english_data = [sentence.rstrip('\\n') for sentence in english_data]\n",
        "hindi_data = [sentence.rstrip('\\n') for sentence in hindi_data]"
      ],
      "metadata": {
        "id": "kGe6uODJwgML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetching unique characters\n",
        "eng_char = set([char for sent in english_data for char in list(sent)])\n",
        "hin_char = set([char for sent in hindi_data for char in list(sent)])"
      ],
      "metadata": {
        "id": "OskkXKA6u5f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = '<start>'\n",
        "PADDING_TOKEN = '<pad>'\n",
        "END_TOKEN = '<end>'\n",
        "hindi_vocab = [START_TOKEN,'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4',\n",
        "               '5', '6', '7', '8', '9', ':', '=', '>', '?', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ',\n",
        "               'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ',\n",
        "               'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'व', 'श', 'ष', 'स',\n",
        "               'ह', 'ऺ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्','ं','ॐ', 'क़', 'ख़', 'ग़',\n",
        "               'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॢ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९',' ',PADDING_TOKEN,END_TOKEN]\n",
        "\n",
        "english_vocab = [START_TOKEN,'_', 'U', 'P', '=', '.', ',','Z', 'e', '[', '2', ' ', 'E', 'c', 'n', 'F', '-', 'K', 'a',\n",
        "                 'h', 's', 'x', 'N', '7', 'G', 'W', 'V', '>', '&', ')', '5', '?', '\\\\', 'I', ':', 't', 'C', 'z', '~',\n",
        "                 '6', 'J', ']', '/', '#', 'r', '{', 'p', '!', 'M', '*', 'B', '8', '9', 'f', 'Q', '}', '3', 'D', 'H',\n",
        "                 'i', 'g', '@', 'b', 'm', 'R', '%', 'L', '\"', '^', '$', '0', 'X', 'A', '4',\n",
        "                 '(', 'u', 'd', 'q', '`', 'y', 'T', \"'\", 'Y', 'S', 'o', 'v', 'k', '|', '+', 'l', '1', 'O', 'j', '<', 'w',PADDING_TOKEN,END_TOKEN]"
      ],
      "metadata": {
        "id": "uHL0ZxyjvzOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_hindi  = {k:v for k , v in enumerate(hindi_vocab)}\n",
        "hindi_to_idx = {v:k for k , v in enumerate(hindi_vocab)}\n",
        "idx_to_english = {k:v for k , v in enumerate(english_vocab)}\n",
        "english_to_idx ={v:k for k,v in enumerate(english_vocab)}"
      ],
      "metadata": {
        "id": "bSgcug1SyzDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text,langDict=None):\n",
        "    return [langDict[i] for i in list(text)]\n",
        "def decode(idx,langDict=None):\n",
        "    return ''.join([langDict[i] for i in idx])"
      ],
      "metadata": {
        "id": "xgralTkx0EVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hindi_data[0])\n",
        "print(list(hindi_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wusMwmSHXZBn",
        "outputId": "af74f016-6c85-444e-ad13-1e32a718c58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "जिसके जवाब में पाक ने अच्छी शुरुआत की थी.\n",
            "['ज', 'ि', 'स', 'क', 'े', ' ', 'ज', 'व', 'ा', 'ब', ' ', 'म', 'े', 'ं', ' ', 'प', 'ा', 'क', ' ', 'न', 'े', ' ', 'अ', 'च', '्', 'छ', 'ी', ' ', 'श', 'ु', 'र', 'ु', 'आ', 'त', ' ', 'क', 'ी', ' ', 'थ', 'ी', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = encode(hindi_data[0],langDict=hindi_to_idx)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxfXee6qXbgF",
        "outputId": "0054a7ef-d1a2-4725-ae97-291db6872bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[53, 86, 80, 46, 93, 123, 53, 77, 85, 69, 123, 71, 93, 100, 123, 67, 85, 46, 123, 65, 93, 123, 30, 51, 99, 52, 87, 123, 78, 88, 73, 88, 31, 61, 123, 46, 87, 123, 62, 87, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(x,langDict=idx_to_hindi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWKk4gPnYA2k",
        "outputId": "c5d59bad-c75a-4f30-8001-d343c5254993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "जिसके जवाब में पाक ने अच्छी शुरुआत की थी.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max([len(i) for i in hindi_data]) , max([len(i) for i in english_data])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR82QNNpYPyc",
        "outputId": "fbe7a125-dd20-40ee-9af8-5b9346442b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1171, 1208)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length hindi: {np.percentile([len(x) for x in hindi_data], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_data], PERCENTILE)}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR9T_-JkceFk",
        "outputId": "574e7882-a458-420c-a96b-ac9b01a5224b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97th percentile length hindi: 259.0\n",
            "97th percentile length English: 266.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 280\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence,max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length-1) #need to re-add the end token so leaving 1 space\n",
        "\n",
        "\n",
        "valid_sentence_indices = []\n",
        "\n",
        "for index  in range(len(hindi_data)):\n",
        "    hindi_sentence , english_sentence = hindi_data[index] , english_data[index]\n",
        "    if is_valid_length(hindi_sentence, max_sequence_length) and is_valid_length(english_sentence , max_sequence_length) and is_valid_tokens(hindi_sentence , hindi_vocab):\n",
        "        valid_sentence_indices.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(hindi_data)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indices)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRHLn6dOc4nO",
        "outputId": "a282683f-58f9-4fdd-dccb-20b688316cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 70000\n",
            "Number of valid sentences: 55129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentences = [hindi_data [i] for i in valid_sentence_indices]\n",
        "english_sentences = [english_data[i] for i in valid_sentence_indices]\n",
        "print(len(hindi_sentences) , len(english_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou73d_1yeaXd",
        "outputId": "1db00bc6-0146-4edb-cc7b-71a9a56bcef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55129 55129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset , DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self,english_sentences, hindi_sentences):\n",
        "        self.hindi_sentences = hindi_sentences\n",
        "        self.english_sentences = english_sentences\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "        return self.hindi_sentences[idx] , self.english_sentences[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hindi_sentences)\n",
        "\n"
      ],
      "metadata": {
        "id": "2B3wwZacey8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(english_sentences, hindi_sentences)\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWksNUTrfbep",
        "outputId": "1dd6084c-b154-46ca-efbc-0c9551bffa25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55129"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB-VnRKZffAp",
        "outputId": "6f5b16d0-ad18-42de-fb87-6bf3b10e718b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत्र का प्रतिनिधित्व करते हैं.',\n",
              " 'The Congress leader represents Sivaganga Lok Sabha segment from Tamil Nadu.')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvEKZkfBfl2J",
        "outputId": "b9c74db3-6716-4345-8081-049496fa0714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('जिसके जवाब में पाक ने अच्छी शुरुआत की थी.', 'कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत्र का प्रतिनिधित्व करते हैं.', 'संबंधन प्रयास के बारे में उपयोक्ता को प्रांप्ट करें'), ('In reply, Pakistan got off to a solid start.', 'The Congress leader represents Sivaganga Lok Sabha segment from Tamil Nadu.', 'Prompt the user about connection attempts')]\n",
            "[('वित्त मंत्री ने घोषणा कि जमा बीमा और ऋण गारंटी निगम (डीआईसीजीसी) को जमा राशि बीमा का दायरा, जो इस समय 1 लाख रुपये है उसे बढ़ाकर प्रति जमाकर्ता 5 लाख रुपये करने की अनुमति प्रदान कर दी गई है।', 'इस कारण हे भाइयों, अपने बुलाए जाने, और चुन लिये जाने को सिद्ध करने का भली भांति यत्न करते जाओ, क्योंकि यदि ऐसा करोगे, तो कभी भी ठोकर न खाओगे।', 'समिति में जिला एवं सत्र न्यायाधीश, कलेक्टर, पुलिस अधीक्षक व जिला विधिक सेवा प्राधिकरण के सचिव शामिल रहते हैं।'), ('Further, the Minister announced that Deposit Insurance and Credit Guarantee Corporation (DICGC) has been permitted to increase Deposit Insurance coverage to Rs.', 'Therefore, brothers, be more diligent to make your calling and election sure. For if you do these things, you will never stumble.', 'The review committee meeting chaired by the District Judges will be attended by Collectors, SPs, Superintendents of jails and Secretary of District Legal Services Authority.')]\n",
            "[('पुलिस मौके पर मौजूद है।', 'जम्मू एवं कश्मीर विधानसभा के लिए दूसरे चरण के तहत होने वाले मतदान के लिए प्रधानमंत्री नरेंद्र मोदी भारतीय जनता पार्टी (भाजपा) के पक्ष में शुक्रवार को यहां रैलियां करेंगे।', 'और 3050एमएएच की दमदार बैटरी से लैस है।'), ('Police is present on the spot.', 'Prime Minister Narendra Modi is slated to campaign for BJP in second phase of Assembly elections in Udhampur and Poonch district of Jammu and Kashmir tomorrow', 'It has a battery backup of 3050mAh.')]\n",
            "[('\"उन्होंने कहा, \"\"बाबू रघुवंश प्रसाद जी ने भी गरीबों के लिए काम किया।\"', 'इस विमान हादसे में सभी 176 यात्रियों की मौत हो गई थी.', '\"राहुल ने कहा, \"\"मैं वही सवाल फिर से पूछता हूं।\"'), ('\"Similarly, Babu Raghuvansh Prasad Singh ji also worked for poor,\"\" he said in his address.\"', 'All 176 passengers died in the incident.', 'I will ask the same question again.')]\n",
            "[('आमंत्रित नहीं किया', 'सनी लियोन श्रृंखला में एक विशेषज्ञ की भूमिका निभाती हैं।', 'इसके बाद जब य सुख जाए तो इसे साफ पानी से धो लें।'), ('Not invited', 'Sunny Leone plays a paranormal expert in the series.', 'Then after it becomes dry, rinse off with water.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence , language_to_index, start_token=True, end_token=True):\n",
        "    sentence_word_indices = [language_to_index[token] for token in list(sentence)]\n",
        "    if start_token:\n",
        "        sentence_word_indices.insert(0,language_to_index[START_TOKEN])\n",
        "    if end_token:\n",
        "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
        "    for _ in range(len(sentence_word_indices) , max_sequence_length):\n",
        "        sentence_word_indices.append(language_to_index[PADDING_TOKEN])\n",
        "    return torch.tensor(sentence_word_indices)"
      ],
      "metadata": {
        "id": "a4TR2Cbtjl0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_to_idx[PADDING_TOKEN]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu7nmRbursqc",
        "outputId": "ee07ec8c-7415-486f-d27a-2c1ab4293101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrByFJBqlGVl",
        "outputId": "052fce53-8f94-4b05-f814-5095fbdb92b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('आमंत्रित नहीं किया',\n",
              "  'सनी लियोन श्रृंखला में एक विशेषज्ञ की भूमिका निभाती हैं।',\n",
              "  'इसके बाद जब य सुख जाए तो इसे साफ पानी से धो लें।'),\n",
              " ('Not invited',\n",
              "  'Sunny Leone plays a paranormal expert in the series.',\n",
              "  'Then after it becomes dry, rinse off with water.')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrYSVXOhlzoI",
        "outputId": "97469a9a-5a96-408f-ef7d-cbfa1494fe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized, hindi_tokenized = [], []\n",
        "for sentence_num in range(batch_size):\n",
        "    hindi_sentence, eng_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "    eng_tokenized.append( tokenize(eng_sentence, english_to_idx, start_token=False, end_token=False) )\n",
        "    hindi_tokenized.append(tokenize(hindi_sentence, hindi_to_idx, start_token=True, end_token=True) )\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "hindi_tokenized = torch.stack(hindi_tokenized)"
      ],
      "metadata": {
        "id": "t_VeQ9sSlVh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "thbwROaGlxGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG0kXbDpnSwp",
        "outputId": "22c59774-5236-4b1e-c8c8-47e26fa2c110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22, 84, 35, 11, 59, 14, 85, 59, 35,  8, 76, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95],\n",
              "        [83, 75, 14, 14, 79, 11, 66,  8, 84, 14,  8, 11, 46, 89, 18, 79, 20, 11,\n",
              "         18, 11, 46, 18, 44, 18, 14, 84, 44, 63, 18, 89, 11,  8, 21, 46,  8, 44,\n",
              "         35, 11, 59, 14, 11, 35, 19,  8, 11, 20,  8, 44, 59,  8, 20,  5, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95],\n",
              "        [80, 19,  8, 14, 11, 18, 53, 35,  8, 44, 11, 59, 35, 11, 62,  8, 13, 84,\n",
              "         63,  8, 20, 11, 76, 44, 79,  6, 11, 44, 59, 14, 20,  8, 11, 84, 53, 53,\n",
              "         11, 94, 59, 35, 19, 11, 94, 18, 35,  8, 44,  5, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_tokenized[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ttYbbrnS3y",
        "outputId": "06401ba2-8c00-418e-c4c3-aa6c6760dbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0,  31,  71, 100,  61,  99,  73,  86,  61, 123,  65,  81,  87, 100,\n",
              "        123,  46,  86,  72,  85, 125, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
              "        124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch , hindi_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length , max_sequence_length], True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences , max_sequence_length ,max_sequence_length],False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    #here we are making padding mask of size (batch , max_len , max_len) because we are going to add this\n",
        "    #after query * transpose(key) so suppose size of query is (batch,num_heads,seq_len,head_dim) and will do transpose of\n",
        "    #key on last 2 dimensions which are seq_len,head_dim to make key dimensions - (batch,num_heads,head_dim,seq_len)\n",
        "    #after matrix multiplication will get (batch, num_heads, seq_len, seq_len) so basically we are getting of scores of each words/chars\n",
        "    #wrt to other words/chars so will mask the padding token by adding padding_mask matrix.\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, hindi_sentence_length = len(eng_batch[idx]), len(hindi_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      hindi_chars_to_padding_mask = np.arange(hindi_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      #print(encoder_padding_mask.shape , encoder_padding_mask)\n",
        "      decoder_padding_mask_self_attention[idx, :, hindi_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, hindi_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, hindi_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    #print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :20, :20]}\")\n",
        "    #print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
        "    #print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n"
      ],
      "metadata": {
        "id": "Ci0_EdLxnYyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#x , _ , _ = create_masks(batch[0], batch[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNDJxrIrt9Z7",
        "outputId": "ce1c2dc6-f5ff-412d-ba2a-f3810ddf5cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_self_attention_mask torch.Size([3, 280, 280]): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]])\n",
            "decoder_self_attention_mask torch.Size([3, 280, 280]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
            "decoder_cross_attention_mask torch.Size([3, 280, 280]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7zNCRpvuASw",
        "outputId": "47ad0ca1-0024-4778-b0a1-ac840aefdcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsYtufxK-aPm",
        "outputId": "1bcb9faf-b10c-43ea-b286-a5746768dc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('आमंत्रित नहीं किया',\n",
              "  'सनी लियोन श्रृंखला में एक विशेषज्ञ की भूमिका निभाती हैं।',\n",
              "  'इसके बाद जब य सुख जाए तो इसे साफ पानी से धो लें।'),\n",
              " ('Not invited',\n",
              "  'Sunny Leone plays a paranormal expert in the series.',\n",
              "  'Then after it becomes dry, rinse off with water.')]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pRy_jNhy-m5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}